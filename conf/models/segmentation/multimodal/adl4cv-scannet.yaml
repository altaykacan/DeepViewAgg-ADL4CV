# @package models
defaults:
  - segmentation/default
base-intermediate:
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 16
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            out_feat_img_0: 128  # out dim of the pretrained net

        down_conv:
            module_name: ResNetDown
            block: block
            #conv3d_after_fusion: False # conv->fusion
            conv3d_before_fusion: False # fusion->conv
            N: [ 0, 1, 1, 1, 1 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            n_early_conv: 0
            down_conv_nn:
              [
                  [ FEAT , 4*in_feat ],
                  [ 4*in_feat + out_feat_img_0, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat , 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer0 # Needs to be truncated
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: 1
                out_channels: 4*in_feat + out_feat_img_0  # This is necessary to support batches with no images
#                 checkpointing: cav

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]

Res16UNet34-L4-early-ade20k-interpolate-concat-fusion:
    # 28.1 M params - 109.4 Mo on the GPU - ~2.7 ko/pixel at training time
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 32
            in_feat_img: 4
            in_feat_map: 8
            in_feat_attention: 4
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            l4: 512  # out dim of ResNet18Layer4

        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 2, 3, 4, 6 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT + l4, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer4
                    frozen: False
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: GroupBimodalCSRPool
                    in_map: 8
                    in_mod: l4
                    num_groups: 4
                    use_mod: False
                    map_encoder: DeepSetFeat
                    use_num: True
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: 0
                checkpointing: av
                interpolate: True

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]


Res16UNet34-L4-intermediate-ade20k-interpolate-local-fusion:
    # 28.1 M params - 109.4 Mo on the GPU - ~2.7 ko/pixel at training time
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 32
            in_feat_img: 4
            in_feat_map: 8
            embed_2d: 256 
            embed_3d: 256
            attention_samples: 16
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            l4: 512  # out dim of ResNet18Layer4

        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 2, 3, 4, 6 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer4
                    frozen: False
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: GroupBimodalCSRPool
                    in_map: 8
                    in_mod: l4
                    num_groups: 4
                    use_mod: False
                    map_encoder: DeepSetFeat
                    use_num: True
                fusion:
                    module_name: SelfAttentiveBimodalFusion
                    mode: local
                    in_main: 8*in_feat
                    in_mod: l4
                    embed_main: embed_3d
                    embed_mod: embed_2d
                    nsample: attention_samples # 16 nearest neighbors
                branching_index: 5
                #out_channels: 8*in_feat + l4
                checkpointing: av
                interpolate: True

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ embed_2d + embed_3d, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]


Res16UNet34-L3-intermediate-ade20k-interpolate-local-fusion:
    # 28.1 M params - 109.4 Mo on the GPU - ~2.7 ko/pixel at training time
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 32
            in_feat_img: 4
            in_feat_map: 8
            embed_2d: 128 
            embed_3d: 128
            attention_samples: 16
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            l0: 128
            l1: 64
            l2: 128
            l3: 256
            l4: 512  # out dim of ResNet18Layer4

        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 2, 3, 4, 6 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer3
                    frozen: False
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: GroupBimodalCSRPool
                    in_map: 8
                    in_mod: l3
                    num_groups: 4
                    use_mod: False
                    map_encoder: DeepSetFeat
                    use_num: True
                fusion:
                    module_name: SelfAttentiveBimodalFusion
                    mode: local
                    in_main: 8*in_feat
                    in_mod: l3
                    embed_main: embed_3d
                    embed_mod: embed_2d
                    nsample: attention_samples # 16 nearest neighbors
                branching_index: 5
                #out_channels: 8*in_feat + l4
                checkpointing: av
                interpolate: True

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ embed_2d + embed_3d, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]


Res16UNet34-L4-intermediate-ade20k-interpolate-concat-fusion:
    # 28.1 M params - 109.4 Mo on the GPU - ~2.7 ko/pixel at training time
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 32
            in_feat_img: 4
            in_feat_map: 8
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            l4: 512  # out dim of ResNet18Layer4

        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 2, 3, 4, 6 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer4
                    frozen: False
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: GroupBimodalCSRPool
                    in_map: 8
                    in_mod: l4
                    num_groups: 4
                    use_mod: False
                    map_encoder: DeepSetFeat
                    use_num: True
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: 5
                checkpointing: av
                interpolate: True

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat + l4, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]

Res16UNet34-L4-ade20k-interpolate-no2d:
    # 28.1 M params - 109.4 Mo on the GPU - ~2.7 ko/pixel at training time
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 32
            in_feat_img: 4
            in_feat_map: 8
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            l0: 128
            l4: 512  # out dim of ResNet18Layer4

        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 2, 3, 4, 6 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer0
                    frozen: True
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                fusion:
                    module_name: BimodalFusion
                    mode: no2d
                branching_index: 5
                checkpointing: av
                interpolate: True

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]

base-early:
    # 28.1 M params - 109.4 Mo on the GPU - ~2.7 ko/pixel at training time
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 2
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            out_feat_img_0: 128  # out dim of the pretrained net
            out_feat_img_4: 512
            # LAYERS OUT[128, 64, 128, 256, 512]

        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 1, 1, 1, 1 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT + out_feat_img_4, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer4 # Needs to be truncated
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: 0
                out_channels: FEAT + out_feat_img_4  # This is necessary to support batches with no images
#                 checkpointing: cav

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]

base-early-local-fusion:
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 2
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            out_feat_img_0: 128  # out dim of CityscapesResNet18
            out_feat_img_4: 512
            attention_out: 16
            # LAYERS OUT[128, 64, 128, 256, 512]
        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False # conv -> fusion
            N: [ 0, 1, 1, 1, 1 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT + attention_out, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer0
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                fusion:
                    module_name: SelfAttentiveBimodalFusion
                    mode: local
                    in_main: FEAT
                    in_mod: out_feat_img_0 # Channel depth after the first resnet layer
                    out_main: FEAT + attention_out
                    nc_inner: 8 # Dimension of inner embedding
                    nc_qk: 8 # Dimension of queries and keys
                    nsample: 16 # 16 nearest neighbors
                branching_index: 0 # Intermediate fusion at the end of encoder
                out_channels: FEAT + attention_out # This is necessary to support batches with no images
#                 checkpointing: cav

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]

base-late:
    class: sparseconv3d.LateFeatureFusion
    conv_type: "SPARSE"
    backend: "torchsparse"
    mode: concatenation

    backbone_3d: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 2
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py

        down_conv:
            module_name: ResNetDown
            block: block
            N: [ 0, 1, 1, 1, 1 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT, in_feat ],
                  [ in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [2, 2, 2, 2, 3]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
              [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
              ]

    backbone_no3d:
        down_conv:
            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer4
                    frozen: False
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                fusion:
                    module_name: BimodalFusion
                    mode: modality
                branching_index: 0

early-deep-set-local-fusion:
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 2
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            out_feat_img_0: 128  # out dim of CityscapesResNet18
            out_feat_img_4: 512
            attention_out: 16
            # LAYERS OUT[128, 64, 128, 256, 512]
        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False # conv -> fusion
            N: [ 0, 1, 1, 1, 1 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT  + attention_out, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer0
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: GroupBimodalCSRPool
                    in_map: 8
                    in_mod: out_feat_img_0
                    num_groups: 4
                    use_mod: False
                    map_encoder: DeepSetFeat
                    use_num: True
                fusion:
                    module_name: SelfAttentiveBimodalFusion
                    mode: local
                    in_main: FEAT
                    in_mod: out_feat_img_0 # Channel depth after the first resnet layer
                    out_main: FEAT + attention_out
                    nc_inner: 8 # Dimension of inner embedding
                    nc_qk: 8 # Dimension of queries and keys
                    nsample: 16 # 16 nearest neighbors
                branching_index: 0 # Intermediate fusion at the end of encoder
                out_channels: FEAT + attention_out # This is necessary to support batches with no images
#                 checkpointing: cav

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]

early-deep-set-concat:
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 2
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            out_feat_img_0: 128  # out dim of CityscapesResNet18
            # LAYERS OUT[128, 64, 128, 256, 512]
        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False # conv -> fusion
            N: [ 0, 1, 1, 1, 1 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT  + out_feat_img_0, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: ADE20KResNet18TruncatedLayer0
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: GroupBimodalCSRPool
                    in_map: 8
                    in_mod: out_feat_img_0
                    num_groups: 4
                    use_mod: False
                    map_encoder: DeepSetFeat
                    use_num: True
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: 0 # Intermediate fusion at the end of encoder
                out_channels: FEAT + out_feat_img_0 # This is necessary to support batches with no images
#                 checkpointing: cav

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]