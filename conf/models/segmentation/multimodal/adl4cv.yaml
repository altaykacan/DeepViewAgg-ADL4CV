# @package models

base:
    # 28.1 M params - 109.4 Mo on the GPU - ~2.7 ko/pixel at training time
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 2
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            out_feat_img_0: 128  # out dim of CityscapesResNet18

        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 1, 1, 1, 1 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT + out_feat_img_0, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: CityscapesResNet18TruncatedLayer0
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: 0
                out_channels: FEAT + out_feat_img_0  # This is necessary to support batches with no images
#                 checkpointing: cav

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]

base-csr-pooling:
    # 28.1 M params - 109.4 Mo on the GPU - ~2.7 ko/pixel at training time
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 2
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            out_feat_img_0: 128  # out dim of CityscapesResNet18

        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 1, 1, 1, 1 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT + out_feat_img_0, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: CityscapesResNet18TruncatedLayer0
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: GroupBimodalCSRPool
                    in_map: 8
                    in_mod: out_feat_img_0
                    num_groups: 4
                    use_mod: False
                    map_encoder: DeepSetFeat
                    use_num: True
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: 0
                out_channels: FEAT + out_feat_img_0  # This is necessary to support batches with no images
#                 checkpointing: cav

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]


base-qkv-early: # TODO: Get the right setup for the QKVBimodalCSRPool. Jakob: "I think QKV doesnt really make sense with early fusion since there are no features from 3D that can be used for Q"
    # 28.1 M params - 109.4 Mo on the GPU - ~2.7 ko/pixel at training time
    class: sparseconv3d.APIModel
    conv_type: "SPARSE"
    backend: "torchsparse"
    backbone: # backbone offset specific for Sparse conv application builder
        define_constants:
            in_feat: 2
            block: ResBlock # Can be any of the blocks in modules/MinkowskiEngine/api_modules.py
            out_feat_img_0: 128  # out dim of CityscapesResNet18

        down_conv:
            module_name: ResNetDown
            block: block
            conv3d_after_fusion: False
            N: [ 0, 1, 1, 1, 1 ]
            kernel_size: [ 3, 2, 2, 2, 2 ]
            stride: [ 1, 2, 2, 2, 2 ]
            down_conv_nn:
              [
                  [ FEAT + out_feat_img_0, 4*in_feat ],
                  [ 4*in_feat, in_feat ],
                  [ in_feat, 2*in_feat ],
                  [ 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, 8*in_feat ],
              ]

            image:
                down_conv:
                    module_name: CityscapesResNet18TruncatedLayer0
                atomic_pooling:
                    module_name: BimodalCSRPool
                    mode: max
                view_pooling:
                    module_name: QKVBimodalCSRPool
                    in_main: 1
                    in_map: 8
                    in_mod: [ l0 ]
                    out_mod: [ l0_map]
                    num_groups: 4
                    use_mod_q: False
                    use_mod_k: False
                    map_encoder: DeepSetFeat
                    use_num: True
                fusion:
                    module_name: BimodalFusion
                    mode: concatenation
                branching_index: 0
                out_channels: FEAT + out_feat_img_0  # This is necessary to support batches with no images
#                 checkpointing: cav

        up_conv:
            block: block
            module_name: ResNetUp
            N: [ 1, 1, 1, 1, 1 ]
            kernel_size: [ 2, 2, 2, 2, 3 ]
            stride: [ 2, 2, 2, 2, 1 ]
            up_conv_nn:
                [
                  [ 8*in_feat, 4*in_feat, 4*in_feat ],
                  [ 4*in_feat, 2*in_feat, 4*in_feat ],
                  [ 4*in_feat, in_feat, 3*in_feat ],
                  [ 3*in_feat, 4*in_feat, 3*in_feat ],
                  [ 3*in_feat, 0, 3*in_feat ],
                ]
